{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DjpixraCUjOzXhScr7OHNyJuwspXIuq4",
      "authorship_tag": "ABX9TyOn4zTsVYub8niRZhUkAdR1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARtoRiAs10/MeloSynthiaAI/blob/Model/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EEepSu1I8Y8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5952c16-b826-4480-db15-e0c1c0e8c815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SlUIf5wD8nx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "\n",
        "import os\n",
        "\n",
        "import csv\n"
      ],
      "metadata": {
        "id": "JECTNm9h8pFh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_probability as tpa\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from IPython import display\n",
        "from IPython.display import clear_output\n",
        "\n"
      ],
      "metadata": {
        "id": "UGBc47zGOoRm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "pip install tensorflow-addons==0.19.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N1gSAHDhTCh",
        "outputId": "6f932a06-ab15-40f9-8b32-ee6bf1bfa17c",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==0.19.0\n",
            "  Downloading tensorflow_addons-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==0.19.0) (23.1)\n",
            "Collecting typeguard>=2.7 (from tensorflow-addons==0.19.0)\n",
            "  Downloading typeguard-4.1.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from typeguard>=2.7->tensorflow-addons==0.19.0) (4.7.1)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0 typeguard-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "T4-Ntc3khody"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import imageio\n",
        "import time\n",
        "import IPython.display as ipd\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "metadata": {
        "id": "eCI-eHpPPWy3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YeWuW9ezLMNR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T7jsdn_ZOnaX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtccLwAjLNqq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ymyd9XpOZwr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import session\n",
        "seed=123\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.compat.v1.keras.backend.set_session(sess)"
      ],
      "metadata": {
        "id": "hltojl9bOaJx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5ky6lUsvUgq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 60000\n",
        "BATCH_SIZE= 10\n",
        "test_size=10000\n",
        "epochs=20\n",
        "\n",
        "latent_dim=2\n",
        "num_examples_to_generate = 10\n",
        "\n",
        "BASE_PATH = '..'"
      ],
      "metadata": {
        "id": "DyCCR51hRVp-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sEjoG2B7Y23c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQSqtsAtR0oV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing\n"
      ],
      "metadata": {
        "id": "6Y_ZRWqMR7i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def DatasetLoader(genres,class_):\n",
        "  music_list = np.array(sorted(os.listdir(BASE_PATH+'/'+genres+'/'+class_)))\n",
        "  train_music_1= list(music_list[[0,52,19,39,71,12,75,85,3,45,24,46,88]])\n",
        "\n",
        "  train_music_2= list(music_list[[4,43,56,55,45,31,11,13,70,3,7,21,78]])\n",
        "\n",
        "  TrackSet_1 = [(BASE_PATH)+'/'+class_+'/%$'%(x) for x in train_music_1]\n",
        "\n",
        "  TrackSet_2 = [(BASE_PATH)+'/'+class_+'/%$'%(x) for x in train_music_2]\n",
        "\n",
        "\n",
        "  return TrackSet_1, TrackSet_2"
      ],
      "metadata": {
        "id": "nyKjGrBfSDmS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(file_):\n",
        "  data_, sampling_rate= librosa.load(file_,sr=3000, offset=0.0, duration=30)\n",
        "\n",
        "  data_ = data_.reshape(1,90001)\n",
        "  return data_\n",
        "\n",
        "map_data = lambda filename: tf.compat.v1.py_func(load, [filename], [tf.float32])\n"
      ],
      "metadata": {
        "id": "wlrdOReQUWSe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "TrackSet_1, TrackSet_2 = DatasetLoader('genres','jazz')"
      ],
      "metadata": {
        "id": "SLZWG_4NVq06",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ew9uC8HuVrDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample original **music**"
      ],
      "metadata": {
        "id": "drq5SVyyWKlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = TrackSet_1[1]\n",
        "\n",
        "sample_, sampling_rate= librosa.load(sample, sr=3000, offset=0.0, duration=30)\n",
        "\n",
        "ipd.audio (sample_,rate=3000)\n"
      ],
      "metadata": {
        "id": "SHWOQ3w9WPZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "plt.figure(figsize=(18,15))\n",
        "\n",
        "for i in range(4):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  j = load(TrackSet_1[i])\n",
        "  librosa.display.AdaptiveWaveplot(j[0], sr=3000)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ui12PBGYXeTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset =(\n",
        "    tf.data.Dataset.from_tensor_slices((TrackSet_1)).map(map_data, num_parallel_calls=AUTOTUNE).shuffle(3).batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "test_dataset=(\n",
        "    tf.data.Dataset.from_tensor_slices((TrackSet_2))\n",
        "    .map(map_data, num_parallel_calls=AUTOTUNE)\n",
        "    .shuffle(3)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "Fa7IvPHzYRwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_LxcA5UXejg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V4G-718kXeyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Network architecture\n"
      ],
      "metadata": {
        "id": "jOG96ezZaBK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet1DBlock(tf.keras.Model):\n",
        "    def __init__(self, kernel_size, filters, type = 'encode', prefix = ''):\n",
        "        super(Resnet1DBlock, self).__init__()\n",
        "\n",
        "        if type == 'encode':\n",
        "            self.conv1a = layers.Conv1D(filters, kernel_size, 2, padding = \"same\", \\\n",
        "                                        name = prefix + 'conv1a')\n",
        "            self.conv1b = layers.Conv1D(filters, kernel_size, 1, padding = \"same\", \\\n",
        "                                        name = prefix + 'conv1b')\n",
        "            self.norm1a = tfa.layers.InstanceNormalization(name =  prefix + 'norm1a')\n",
        "            self.norm1b = tfa.layers.InstanceNormalization(name =  prefix + 'norm1b')\n",
        "        elif type == 'decode':\n",
        "            self.conv1a = layers.Conv1DTranspose(filters, kernel_size, 1, padding = \"same\", \\\n",
        "                                                name =  prefix + 'conv1a')\n",
        "            self.conv1b = layers.Conv1DTranspose(filters, kernel_size, 1, padding = \"same\", \\\n",
        "                                                name =  prefix + 'conv1b')\n",
        "            self.norm1a = tf.keras.layers.BatchNormalization(name =  prefix + 'norm1a')\n",
        "            self.norm1b = tf.keras.layers.BatchNormalization(name =  prefix + 'norm1b')\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        x = tf.nn.relu(input_tensor)\n",
        "        x = self.conv1a(x)\n",
        "        x = self.norm1a(x)\n",
        "        x = layers.LeakyReLU(0.4)(x)\n",
        "\n",
        "        x = self.conv1b(x)\n",
        "        x = self.norm1b(x)\n",
        "        x = layers.LeakyReLU(0.4)(x)\n",
        "\n",
        "        x += input_tensor\n",
        "        return tf.nn.relu(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "NjC93o2kaJ5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, latent_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape = (1, 90001), name = 'input_encoder'),\n",
        "\n",
        "                layers.Conv1D(64, 1, 2, name = 'conv1_layer1'),\n",
        "                Resnet1DBlock(64, 1, 'encode', prefix = 'res1_'),\n",
        "                layers.Conv1D(128, 1, 2, name = 'conv1_layer2'),\n",
        "                Resnet1DBlock(128, 1, 'encode', prefix = 'res2_'),\n",
        "                layers.Conv1D(128, 1, 2, name = 'conv1_layer3'),\n",
        "                Resnet1DBlock(128, 1, 'encode', prefix = 'res3_'),\n",
        "                layers.Conv1D(256, 1, 2, name = 'conv1_layer4'),\n",
        "                Resnet1DBlock(256, 1, 'encode', prefix = 'res4_'),\n",
        "\n",
        "                layers.Flatten(name = 'flatten'),\n",
        "                layers.Dense(latent_dim + latent_dim, name = 'dense'),\n",
        "            ]\n",
        "        )\n",
        "        self.decoder = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape = (latent_dim,), name = 'input_decoder'),\n",
        "                layers.Reshape(target_shape = (1, latent_dim)),\n",
        "                Resnet1DBlock(512, 1, 'decode', prefix = 'res1_'),\n",
        "                layers.Conv1DTranspose(512, 1, 1, name = 'Conv1Trans_Layer1'),\n",
        "                Resnet1DBlock(256, 1, 'decode', prefix = 'res2_'),\n",
        "                layers.Conv1DTranspose(256, 1, 1, name = 'Conv1Trans_Layer2'),\n",
        "                Resnet1DBlock(128, 1, 'decode', prefix = 'res3_'),\n",
        "                layers.Conv1DTranspose(128, 1, 1, name = 'Conv1Trans_Layer3'),\n",
        "                Resnet1DBlock(64, 1, 'decode', prefix = 'res4_'),\n",
        "                layers.Conv1DTranspose(64, 1, 1, name = 'Conv1Trans_Layer4'),\n",
        "                layers.Conv1DTranspose(90001, 1, 1, name = 'Conv1Trans_Layer5')\n",
        "            ]\n",
        "        )\n",
        "@tf.function\n",
        "def sample(self, esp=None):\n",
        "      if eps is None:\n",
        "        eps = tf.random.normal(shape=(200, self.latent_dim))\n",
        "      return self.decode(eps, apply_sigmoid=True)\n",
        "@tf.function\n",
        "def encode(self,x):\n",
        "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        "\n",
        "@tf.function\n",
        "def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps* tf.exp(logvar* .5)+ mean\n",
        "@tf.function\n",
        "def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.decoder(z)\n",
        "    if apply_sigmoid:\n",
        "      probs= tf.sigmoid(logits)\n",
        "      return probs\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "220R7UtedmmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.0003,beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
      ],
      "metadata": {
        "id": "UhFZ-gwdCdTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2.* np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5* ((sample - mean)**2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "      axis = raxis\n",
        "  )"
      ],
      "metadata": {
        "id": "FOR5mx7CCyS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_loss(model,x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  x_logit = model.decode(z)\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1,2])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
      ],
      "metadata": {
        "id": "_MOCI6EoCy2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOSS OPTIMIZATION"
      ],
      "metadata": {
        "id": "4HisIZWEGiQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.backend import gradients\n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "   \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "       This function computes the loss and gradients, and uses the latter to\n",
        "       update the model's parameters.\n",
        "     \"\"\"\n",
        "   with tf.GradientTape() as tape:\n",
        "      mean, logvar = model.encode(x)\n",
        "      z = model.reparameterize(mean, logvar)\n",
        "      x_logit = model.decode(z)\n",
        "      cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "      logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2])\n",
        "      logpz = log_normal_pdf(z, 0., 0.)\n",
        "      logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "\n",
        "      loss_KL = -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "      reconstruction_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(x, x_logit))\n",
        "\n",
        "      total_loss = reconstruction_loss + loss_KL\n",
        "      gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "\n",
        "      optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KprE8s2PGl6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_vector_for_generation = tf.random.normal(\n",
        "    shape=[num_examples_to_generate, latent_dim]\n",
        ")\n",
        "\n",
        "model = CVAE(latent_dim)"
      ],
      "metadata": {
        "id": "y0zhvICKfsas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_sample, save):\n",
        "    mean, logvar = model.encode(test_sample)\n",
        "    z = model.reparameterize(mean, logvar)\n",
        "    predictions = model.sample(z)\n",
        "    fig = plt.figure(figsize=(18, 15))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        wave = np.asarray(predictions[i])\n",
        "        librosa.display.waveplot(wave[0], sr=3000)\n",
        "\n",
        "    # tight_layout minimizes the overlap between 2 sub-plots\n",
        "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
        "    plt.savefig('{}_{:04d}.png'.format(save, epoch))\n",
        "    plt.show()\n",
        "# Pick a sample of the test set for g"
      ],
      "metadata": {
        "id": "rduEXEjxxaoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert BATCH_SIZE >= num_examples_to_generate\n",
        "for test_batch in test_dataset.take(1):\n",
        "    test_sample = test_batch[0]"
      ],
      "metadata": {
        "id": "8fl1pNSHyODR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6h54oQZ71Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training model\n"
      ],
      "metadata": {
        "id": "X3HjHIEEPOmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_and_save_images(model, 0, test_sample, 'jazz')\n",
        "def train(train_dataset, test_dataset, model, save):\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        start_time = time.time()\n",
        "        for train_x in train_dataset:\n",
        "            train_x = np.asarray(train_x)[0]\n",
        "            train_step(model, train_x, optimizer)\n",
        "        end_time = time.time()\n",
        "\n",
        "        loss = tf.keras.metrics.Mean()\n",
        "        for test_x in test_dataset:\n",
        "            test_x = np.asarray(test_x)[0]\n",
        "            loss(compute_loss(model, test_x))\n",
        "        display.clear_output(wait=False)\n",
        "        elbo = -loss.result()\n",
        "        print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'.format(epoch,\n",
        "                                                                                       elbo,\n",
        "                                                                                       end_time - start_time\n",
        "                                                                                      ))\n",
        "        generate_and_save_images(model,\n",
        "                                 epoch,\n",
        "                                 test_sample,\n",
        "                                 save)\n",
        "train(train_dataset, test_dataset, model, 'jazz')"
      ],
      "metadata": {
        "id": "BicsThDsPUSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q imageio"
      ],
      "metadata": {
        "id": "J2VBVMF9Qr6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "RSxB-FxcQ1kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anim_file_1 = 'jazz_cvae.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file_1, mode='I') as writer:\n",
        "    filenames = glob.glob('jazz*.png')\n",
        "    filenames = sorted(filenames)\n",
        "    for filename in filenames:\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)"
      ],
      "metadata": {
        "id": "rlR1XAdSQ5Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rk89FKERRFWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#visualization"
      ],
      "metadata": {
        "id": "bNIzChy_R3Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_docs.vis.embed as embed\n",
        "embed.embed_file(anim_file_1)"
      ],
      "metadata": {
        "id": "HFTVnrN_R7K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generated music"
      ],
      "metadata": {
        "id": "UB4QPPnfSAvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(test_dataset, model):\n",
        "    save_music = []\n",
        "    for test in test_dataset:\n",
        "        mean, logvar = model.encode(test)\n",
        "        z = model.reparameterize(mean, logvar)\n",
        "        predictions = model.sample(z)\n",
        "        for pred in predictions:\n",
        "            wave = np.asarray(pred)\n",
        "            save_music.append(wave)\n",
        "    return save_music\n",
        "\n",
        "saved_musics = inference(test_dataset, model)"
      ],
      "metadata": {
        "id": "Ff6nBmaISHYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music1=saved_musics[0][0]\n",
        "ipd.Audio(music1,rate=3000)"
      ],
      "metadata": {
        "id": "qEedsU8kSMFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
